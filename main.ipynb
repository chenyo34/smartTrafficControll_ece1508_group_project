{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMO HOME: /opt/miniconda3/lib/python3.13/site-packages/sumo\n"
     ]
    }
   ],
   "source": [
    "# Import the required packages and libs.\n",
    "from single_intersection import TrafficEnv\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sumo_rl import SumoEnvironment\n",
    "import torch\n",
    "# Print the sumo environment path for further verification \n",
    "print(\"SUMO HOME:\", os.environ.get(\"SUMO_HOME\"))\n",
    "# SUMO HOME: /opt/miniconda3/lib/python3.13/site-packages/sumo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def to_evaluate_agent(\n",
    "        env=None,\n",
    "        agent=\"heuristic\",\n",
    "        steps=1000,\n",
    "        phase_duration=10,\n",
    "        render=False,\n",
    "        seed=42,\n",
    "        to_save = None):\n",
    "    \"\"\" Evaluate the performance of a method in given SUMO env.\"\"\"\n",
    "\n",
    "    # Initialization  ->  file saving \n",
    "    sim_records = []\n",
    "    header = [\n",
    "        \"step\", \n",
    "        \"sim_time\",\n",
    "        \"avg_wait_time\", \n",
    "        # \"total_wait_time\",\n",
    "        \"queue_length\",\n",
    "        \"pressure\",\n",
    "        \"throughput\",\n",
    "        \"avg_speed\",\n",
    "        \"action\",\n",
    "        \"reward\"]\n",
    "    \n",
    "    # Initialization -> simulation loops\n",
    "    obs, info = env.reset(seed=seed)\n",
    "    cur_phase, phase_timer, last_arrived = 0,0,0\n",
    "    done = False \n",
    "\n",
    "    for step in range(steps):\n",
    "        if render: env.render()\n",
    "\n",
    "        # debug \n",
    "        # print(\"Phase Time\" , phase_timer, \"Current Phase: \", cur_phase)\n",
    "\n",
    "        #################################\n",
    "        ###  Action Selection ###\n",
    "        #################################\n",
    "        if agent == \"heuristic\":\n",
    "            # Determine the action\n",
    "            if phase_timer >= phase_duration: # Pre-defined heuristic method\n",
    "                cur_phase = (cur_phase + 1) % env.action_space.n\n",
    "                phase_timer = 0\n",
    "            action = cur_phase\n",
    "            phase_timer += 1\n",
    "        elif agent == \"random\": # Random Method \n",
    "            action = env.action_space.sample()\n",
    "        # else: # Trained RL Agent \n",
    "        #     # action, _ \n",
    "\n",
    "        #################################\n",
    "        ###  Feed action and observe ###\n",
    "        #################################\n",
    "        obs, reward, done, _, info = env.step(action)\n",
    "        sim_time = env.sumo.simulation.getTime()\n",
    "        # veh_ids = env.sumo.simulation.getIDList()\n",
    "        # avg_wait_time = info[\"avg_wait_time\"] # Not sure if it is available\n",
    "\n",
    "\n",
    "        #######################################\n",
    "        ###  Collect and store the metrics ###\n",
    "        #######################################\n",
    "        # wait_time_lst = []\n",
    "        # queue_length = 0\n",
    "        # lane_veh_counts = {}\n",
    "\n",
    "        # for veh in veh_ids:\n",
    "        #     cur_lane = env.sumo.vehicles.getLaneID(veh)\n",
    "        #     cur_speed = env.sumo.vehicles.getSpeed(veh)\n",
    "        #     cur_wait_time = env.sumo.vehicles.getWaitingTime(veh)\n",
    "\n",
    "        #     if cur_speed < 0.1:\n",
    "        #         queue_length += 1\n",
    "        #     lane_veh_counts[cur_lane] = lane_veh_counts.get(cur_lane, 0) + 1\n",
    "\n",
    "        #     # ====== Wait-Time ======\n",
    "        #     wait_time_lst.append(cur_wait_time)\n",
    "        #     # ========================\n",
    "\n",
    "        # # Pressure\n",
    "        # pressure = 0\n",
    "        # for lane, count in lane_veh_counts.items():\n",
    "        #     if 1:\n",
    "        #         # num_incoming += count\n",
    "        #         pressure += count\n",
    "        #     else:\n",
    "        #         num_outgoing += count\n",
    "        #         pressure -= count\n",
    "\n",
    "        # Avg wait and total wait\n",
    "        # avg_wait = np.mean(wait_time_lst) if wait_time_lst else 0\n",
    "        # total_wait = np.sum(wait_time_lst) if wait_time_lst else 0\n",
    "\n",
    "        # Avg speed and total speed\n",
    "        # avg_speed = np.mean(env.sumo.vehicles.getSpeed(vid) for vid in veh_ids)\n",
    "        # total_speed = np.sum(env.sumo.vehicles.getSpeed(vid) for vid in veh_ids)\n",
    "\n",
    "        # Throughput\n",
    "        # total_arrived = env.sumo.simulation.getArrivedNumber()\n",
    "        # throughput = total_arrived - last_arrived\n",
    "        # last_arrived = total_arrived\n",
    "\n",
    "        # Load the records into log\n",
    "        sim_records.append([\n",
    "            step,\n",
    "            sim_time,\n",
    "            info[\"waiting_time\"],\n",
    "            info[\"queue_length\"],\n",
    "            info[\"pressure\"],\n",
    "            info[\"throughput\"],\n",
    "            info[\"avg_speed\"],\n",
    "            action,\n",
    "            reward])\n",
    "\n",
    "        if done:\n",
    "            obs, info = env.reset(seed=seed)\n",
    "            last_arrived = 0\n",
    "        \n",
    "    env.close()\n",
    "\n",
    "    if to_save:\n",
    "        # supposed: results/***_evaluation_records.csv \n",
    "        folder = \"results\"\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "        save_path = os.path.join(folder, f\"{to_save}_evaluation_records.csv\")\n",
    "\n",
    "        with open(save_path, \"w\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(header)\n",
    "            writer.writerows(sim_records)\n",
    "\n",
    "        print(f\"Evaluation records saved to: {save_path}\")\n",
    "\n",
    "        \n",
    "        return sim_records\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yongchen/Documents/MIE/ECE1508F3/smartTrafficControll_ece1508_group_project/single_intersection.py:42: UserWarning: Call to deprecated function getCompleteRedYellowGreenDefinition, use getAllProgramLogics instead.\n",
      "  num_phases = len(self.sumo.trafficlight.getCompleteRedYellowGreenDefinition(self.ts_id)[0].phases)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrying in 1 seconds\n",
      "Step #0.00 (0ms ?*RT. ?UPS, TraCI: 3ms, vehicles TOT 0 ACT 0 BUF 0)                      \n",
      "Step #100.00 (0ms ?*RT. ?UPS, TraCI: 12ms, vehicles TOT 76 ACT 52 BUF 0)                   \n",
      "Evaluation records saved to: results/test_evaluation_records.csv\n"
     ]
    }
   ],
   "source": [
    "sumo_cmd = [\n",
    "    # \"--start\", # Uncomment this line while using the GUI for visualization \n",
    "    \"--no-warnings\", \"true\", # Uncomment this line to \n",
    "    \"-n\", \"single-intersection.net.xml\",\n",
    "    \"-r\", \"single-intersection-vertical.rou.xml\",\n",
    "    \"--step-length\", \"1.0\"\n",
    "]\n",
    "\n",
    "TLS_ID = \"t\"    \n",
    "\n",
    "# import traci\n",
    "# traci.close(False)\n",
    "\n",
    "# Initialize SUMO environment\n",
    "env = TrafficEnv(\n",
    "    sumo_cmd=sumo_cmd,\n",
    "    tls_id=TLS_ID,\n",
    "    gui=False   # show SUMO GUI\n",
    ")\n",
    "\n",
    "logs = to_evaluate_agent(\n",
    "    env=env,\n",
    "    agent=\"heuristic\",\n",
    "    steps=100,\n",
    "    to_save=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from ppo import ActorCritic, compute_gae, collect_rollout\n",
    "from torch import nn\n",
    "from helper_func import plot_traff_metrics\n",
    "\n",
    "# from torch.nn import function as F\n",
    "\n",
    "def train_ppo(\n",
    "    model,\n",
    "    env=None,\n",
    "    GAMMA = 0.99,\n",
    "    GAE_LAMBDA = 0.95,\n",
    "    CLIP_EPS = 0.2,\n",
    "    LR = 3e-3,\n",
    "    ENT_COEF = 0.01,\n",
    "    VF_COEF = 0.5,\n",
    "    MAX_GRAD_NORM = 0.5,\n",
    "    N_STEPS = 256, \n",
    "    N_EPOCHS = 10,        \n",
    "    MINI_BATCH_SIZE = 32, \n",
    "    TOTAL_TIMESTEPS = 4096,\n",
    "    noise = False\n",
    "):\n",
    "    \n",
    "\n",
    "    if env is None:\n",
    "        raise ValueError(\"Please provide a valid environment instance.\")\n",
    "    elif model is None:\n",
    "        raise ValueError(\"Please provide a valid model instance.\")\n",
    "    \n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.n\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    print(\"Observation dim:\", obs_dim)\n",
    "    print(\"Action dim:\", act_dim)\n",
    "\n",
    "    global_step = 0\n",
    "    # episode_returns = []\n",
    "    # current_ep_return = 0.0\n",
    "\n",
    "    obs, info = env.reset()\n",
    "\n",
    "    appended_rewards=[]\n",
    "    appended_avg_speeds=[]\n",
    "    appended_throughputs=[]\n",
    "    appended_waiting_times=[]\n",
    "\n",
    "    while global_step < TOTAL_TIMESTEPS:\n",
    "        \n",
    "        # 1) Global Step: Roll-out sampling\n",
    "        batch = collect_rollout(env, model, N_STEPS)\n",
    "        global_step += N_STEPS\n",
    "\n",
    "        obs_arr = batch[\"obs\"] \n",
    "        actions_arr = batch[\"actions\"]\n",
    "        old_logprobs_arr = batch[\"logprobs\"]\n",
    "        rewards_arr = batch[\"rewards\"]\n",
    "        dones_arr = batch[\"dones\"]\n",
    "        values_arr = batch[\"values\"]\n",
    "        next_value = batch[\"next_value\"]\n",
    "\n",
    "        # 2) Global Step:  Extract the main metric result from the batch\n",
    "        avg_speeds=batch[\"avg_speeds\"]\n",
    "        throughputs=batch[\"throughputs\"]\n",
    "        waiting_times=batch[\"waiting_times\"]\n",
    "\n",
    "        \n",
    "\n",
    "        # 3)  Global Step: Calcuate the advantages and the returns\n",
    "        advantages, returns = compute_gae(\n",
    "            rewards_arr, values_arr, \n",
    "            dones_arr, next_value,\n",
    "            gamma=GAMMA, lam=GAE_LAMBDA\n",
    "        )\n",
    "\n",
    "        #  Global Step: Standarize the advantage for better and faster convergence\n",
    "        advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
    "\n",
    "        #  Global Step: Tensor type conversion \n",
    "        obs_t = torch.tensor(obs_arr, dtype=torch.float32)\n",
    "        actions_t = torch.tensor(actions_arr, dtype=torch.int64)\n",
    "        old_logprobs_t = torch.tensor(old_logprobs_arr, dtype=torch.float32)\n",
    "        advantages_t = torch.tensor(advantages, dtype=torch.float32)\n",
    "        returns_t = torch.tensor(returns, dtype=torch.float32)\n",
    "\n",
    "        # Multiple epochs of updates\n",
    "        dataset_size = N_STEPS\n",
    "        indices = np.arange(dataset_size)\n",
    "\n",
    "        for _ in range(N_EPOCHS):\n",
    "            # Print debug info \n",
    "\n",
    "            np.random.shuffle(indices)\n",
    "            for start in range(0, dataset_size, MINI_BATCH_SIZE):\n",
    "                end = start + MINI_BATCH_SIZE\n",
    "                mb_idx = indices[start:end]\n",
    "\n",
    "                mb_obs = obs_t[mb_idx]\n",
    "                mb_actions = actions_t[mb_idx]\n",
    "                mb_old_logprobs = old_logprobs_t[mb_idx]\n",
    "                mb_advantages = advantages_t[mb_idx]\n",
    "                mb_returns = returns_t[mb_idx]\n",
    "\n",
    "                # Compute log_prob, entropy, value\n",
    "                new_logprobs, entropy, values_pred = model.evaluate_actions(mb_obs, mb_actions)\n",
    "\n",
    "                # ratio = π_θ(a|s) / π_θ_old(a|s)\n",
    "                ratio = torch.exp(new_logprobs - mb_old_logprobs)\n",
    "\n",
    "                # PPO clipped surrogate\n",
    "                surr1 = ratio * mb_advantages\n",
    "                surr2 = torch.clamp(ratio, 1.0 - CLIP_EPS, 1.0 + CLIP_EPS) * mb_advantages\n",
    "                actor_loss = -torch.min(surr1, surr2).mean()\n",
    "\n",
    "                # value function loss\n",
    "                critic_loss = nn.MSELoss()(values_pred, mb_returns)\n",
    "\n",
    "                # entropy for exploring \n",
    "                entropy_loss = -entropy.mean()\n",
    "\n",
    "                loss = actor_loss + VF_COEF * critic_loss + ENT_COEF * entropy_loss\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
    "                optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "        # 4) Compute the result for the current batch for metric measurement \n",
    "        batch_rewards_return = rewards_arr.mean()\n",
    "        batch_speeds_return = avg_speeds.mean()\n",
    "        batch_throughputs_return = throughputs.mean()\n",
    "        batch_waiting_times_return = waiting_times.mean()\n",
    "\n",
    "        appended_rewards.append(batch_rewards_return)\n",
    "        appended_avg_speeds.append(batch_speeds_return)\n",
    "        appended_throughputs.append(batch_throughputs_return)\n",
    "        appended_waiting_times.append(batch_waiting_times_return)\n",
    "\n",
    "    env.close()\n",
    "    torch.save(model.state_dict(), \"ppo_traffic_signal.pth\")\n",
    "    print(\"Training finished, model saved to ppo_traffic_signal.pth\")\n",
    "\n",
    "    # Plotting the eval. graphs\n",
    "    plot_traff_metrics(\n",
    "        appended_rewards,\n",
    "        appended_avg_speeds,\n",
    "        appended_throughputs,\n",
    "        appended_waiting_times\n",
    "    )\n",
    "\n",
    "    # return appended_rewards, appended_avg_speeds, appended_throughputs, appended_waiting_times\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yongchen/Documents/MIE/ECE1508F3/smartTrafficControll_ece1508_group_project/single_intersection.py:42: UserWarning: Call to deprecated function getCompleteRedYellowGreenDefinition, use getAllProgramLogics instead.\n",
      "  num_phases = len(self.sumo.trafficlight.getCompleteRedYellowGreenDefinition(self.ts_id)[0].phases)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #0.00 (0ms ?*RT. ?UPS, TraCI: 3ms, vehicles TOT 0 ACT 0 BUF 0)                      \n",
      " Retrying in 1 seconds\n",
      "Environment setup complete. Ready for Model Initilizaiton...\n"
     ]
    }
   ],
   "source": [
    "from single_intersection import TrafficEnv\n",
    "\n",
    "# SUMO command (headless for speed)\n",
    "sumo_cmd = [\n",
    "    # \"--start\", # Uncomment this line while using the GUI for visualization \n",
    "    \"--no-warnings\", \"true\", # Uncomment this line to \n",
    "    \"-n\", \"single-intersection.net.xml\",\n",
    "    \"-r\", \"single-intersection-vertical.rou.xml\",\n",
    "    \"--step-length\", \"1.0\"\n",
    "]\n",
    "\n",
    "TLS_ID = \"t\"    \n",
    "\n",
    "# Initialize SUMO environment\n",
    "env = TrafficEnv(\n",
    "    sumo_cmd=sumo_cmd,\n",
    "    tls_id=TLS_ID,\n",
    "    gui=False   # show SUMO GUI\n",
    ")\n",
    "\n",
    "# Check if the environment is working \n",
    "obs, info = env.reset()\n",
    "print(\"Environment setup complete. Ready for Model Initilizaiton...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Starting training...\n"
     ]
    }
   ],
   "source": [
    "model_params  = {\n",
    "    \"obs_dim\": env.observation_space.shape[0],\n",
    "    \"act_dim\": env.action_space.n\n",
    "}\n",
    "\n",
    "ppo_model = ActorCritic(**model_params)\n",
    "print(\"Model initialized. Starting training...\")\n",
    "\n",
    "train_params = {\n",
    "    \"model\": ppo_model,\n",
    "    \"env\": env\n",
    "\n",
    "}\n",
    "\n",
    "model_hist = train_ppo(**train_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL agent and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
